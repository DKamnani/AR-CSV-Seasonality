{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code finds the mean AR freq\n",
    "#Done for each algorithm individually \n",
    " \n",
    "import numpy as np\n",
    "import glob\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import dask.array as da\n",
    "import dask\n",
    "import matplotlib as mpl\n",
    "import xarray as xr\n",
    "import numpy.ma as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/N/slate/dkamnani/IVT_MEERA/*.nc\n",
      "<xarray.DataArray 'IVT' (time: 111040, lat: 361, lon: 576)>\n",
      "dask.array<concatenate, shape=(111040, 361, 576), dtype=float32, chunksize=(2928, 361, 576), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-01-01 ... 2017-12-31T21:00:00\n",
      "  * lon      (lon) float64 -180.0 -179.4 -178.8 -178.1 ... 178.1 178.8 179.4\n",
      "  * lat      (lat) float64 -90.0 -89.5 -89.0 -88.5 -88.0 ... 88.5 89.0 89.5 90.0\n",
      "Attributes:\n",
      "    standard_name:   eastward_wind\n",
      "    long_name:       Integrated Water Vapor Transport\n",
      "    units:           kg/m/s\n",
      "    time:            0\n",
      "    fmissing_value:  1000000000000000.0\n",
      "    vmax:            1000000000000000.0\n",
      "    vmin:            -1000000000000000.0\n",
      "    _ChunkSizes:     [  1   1  91 144]\n",
      "    lev:             1000.0\n",
      "    short_name:      IVT\n"
     ]
    }
   ],
   "source": [
    "#Reading data for one algorithm at a time\n",
    "#Path='/N/slate/dkamnani/Cascade_Bard/Data/*.nc4'\n",
    "#Path='/N/slate/dkamnani/Mundhenk/*.nc4'\n",
    "#Path='/N/slate/dkamnani/ClimateNet_DL/*.nc4'\n",
    "#Path='/N/slate/dkamnani/reid250/*.nc4'\n",
    "#Path='/N/slate/dkamnani/guan_waliser/*.nc4'\n",
    "#DS=xr.open_mfdataset(Path,chunks={'time':2928})\n",
    "Path='/N/slate/dkamnani/IVT_MEERA/*.nc'\n",
    "#Path='/N/scratch/dkamnani/vIVT/Final/*.nc'\n",
    "print(Path)\n",
    "DS=xr.open_mfdataset(Path, parallel=True)\n",
    "#Freq=DS.ar_binary_tag\n",
    "Freq=DS.IVT\n",
    "#Freq=da.from_array(Freq)\n",
    "#print(\"The initial dataset is\")\n",
    "print(Freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on DJF\n",
      "Working on MAM\n",
      "Working on JJA\n",
      "Working on SON\n",
      "<xarray.DataArray 'IVT' (season: 4, year: 39, lat: 361, lon: 576)>\n",
      "dask.array<concatenate, shape=(4, 39, 361, 576), dtype=float32, chunksize=(1, 1, 361, 576), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * lon      (lon) float64 -180.0 -179.4 -178.8 -178.1 ... 178.1 178.8 179.4\n",
      "  * lat      (lat) float64 -90.0 -89.5 -89.0 -88.5 -88.0 ... 88.5 89.0 89.5 90.0\n",
      "  * year     (year) int64 1980 1981 1982 1983 1984 ... 2014 2015 2016 2017 2018\n",
      "  * season   (season) <U3 'DJF' 'MAM' 'JJA' 'SON'\n"
     ]
    }
   ],
   "source": [
    "#Calculating the seasonal averages\n",
    "\n",
    "#setting the months for each season\n",
    "seasons = dict(\n",
    "    DJF = [12,  1,  2],\n",
    "    MAM = [ 3,  4,  5],\n",
    "    JJA = [ 6,  7,  8],\n",
    "    SON = [ 9, 10, 11])\n",
    "# initialize the seasonal mean dataset as a list\n",
    "seasonal_mean_dataset = []\n",
    "# loop over seasons\n",
    "for season in seasons:\n",
    "    print(f\"Working on {season}\")\n",
    "    \n",
    "    # determine the month associated with each timestep\n",
    "    data_month = Freq['time.month']\n",
    "    \n",
    "    # determine whether each time step is within the current season (True=yes, False=no)\n",
    "    in_season = np.in1d(data_month, seasons[season])\n",
    "    #print(in_season)\n",
    "    \n",
    "    # subset the data so that only includes months in the current season\n",
    "    Freq_subset = Freq.sel(time = Freq['time'][in_season])\n",
    "    #print(Freq['time'][in_season])\n",
    "    \n",
    "    # set the year values by which we'll group the data\n",
    "    season_years = Freq['time.year']\n",
    "    #print(season_years)\n",
    "    \n",
    "    # for DJF, D and JF have different years, meaning they would be grouped incorrectly\n",
    "    # (Jan 2020, Feb 2020... and Dec 2020 would all be grouped into the same year, whereas we want\n",
    "    #  Dec 2019 to be grouped instead)\n",
    "    # The following artificially shifts the year for december to account for this, so that Dec 2019 becomes 'Dec 2020'\n",
    "    if season == \"DJF\":\n",
    "        # shift data in all decembers ahead by one year so they're grouped with the correct Jan and Feb\n",
    "        season_years[data_month == 12] = season_years[data_month == 12] + 1\n",
    "        \n",
    "    # subset the the season_year variable so we only include months in the current season\n",
    "    season_years = season_years.sel(time = Freq['time'][in_season])\n",
    "        \n",
    "        \n",
    "    # group the data by year (accounting for seasons that span a year change)\n",
    "    year_group = Freq_subset.groupby(season_years)\n",
    "    \n",
    "    # calculate the mean\n",
    "    seasonal_mean = year_group.mean(dim = \"time\")*100\n",
    "    \n",
    "    # append the seasonal mean dataset to the list\n",
    "    seasonal_mean_dataset.append(seasonal_mean)\n",
    "    \n",
    "# create an array of seasons\n",
    "season_array = xr.DataArray(list(seasons), dims = ('season',))\n",
    "#print(season_array)\n",
    "\n",
    "# create a new dataset from the list of seasonal means (overwriting the list)\n",
    "seasonal_mean_dataset = xr.concat(seasonal_mean_dataset, dim = season_array)\n",
    "    \n",
    "# show the dataset\n",
    "print(seasonal_mean_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'IVT' (season: 4, year: 36, lat: 361, lon: 576)>\n",
      "dask.array<getitem, shape=(4, 36, 361, 576), dtype=float32, chunksize=(1, 1, 361, 576), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * lon      (lon) float64 -180.0 -179.4 -178.8 -178.1 ... 178.1 178.8 179.4\n",
      "  * lat      (lat) float64 -90.0 -89.5 -89.0 -88.5 -88.0 ... 88.5 89.0 89.5 90.0\n",
      "  * year     (year) int64 1981 1982 1983 1984 1985 ... 2012 2013 2014 2015 2016\n",
      "  * season   (season) <U3 'DJF' 'MAM' 'JJA' 'SON'\n"
     ]
    }
   ],
   "source": [
    "#slicing the data\n",
    "#removing the first and last year because we need December from the previous year and Jan and Feb from the next\n",
    "seasonal_mean_1=seasonal_mean_dataset.isel(year=slice(1,37))\n",
    "print(seasonal_mean_1)\n",
    "\n",
    "#Saving lat and lon to file\n",
    "lat=seasonal_mean_1.lat\n",
    "lon=seasonal_mean_1.lon\n",
    "lat=np.save('lat.npy',lat)\n",
    "lon=np.save('lon.npy',lon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'IVT' (year: 36, lat: 361, lon: 576)>\n",
      "dask.array<mean_agg-aggregate, shape=(36, 361, 576), dtype=float32, chunksize=(1, 361, 576), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * lon      (lon) float64 -180.0 -179.4 -178.8 -178.1 ... 178.1 178.8 179.4\n",
      "  * lat      (lat) float64 -90.0 -89.5 -89.0 -88.5 -88.0 ... 88.5 89.0 89.5 90.0\n",
      "  * year     (year) int64 1981 1982 1983 1984 1985 ... 2012 2013 2014 2015 2016\n"
     ]
    }
   ],
   "source": [
    "mean_ar=seasonal_mean_1.mean(dim='season',skipna=True)\n",
    "print(mean_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'IVT' (lat: 361, lon: 576)>\n",
      "dask.array<mean_agg-aggregate, shape=(361, 576), dtype=float32, chunksize=(361, 576), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * lon      (lon) float64 -180.0 -179.4 -178.8 -178.1 ... 178.1 178.8 179.4\n",
      "  * lat      (lat) float64 -90.0 -89.5 -89.0 -88.5 -88.0 ... 88.5 89.0 89.5 90.0\n"
     ]
    }
   ],
   "source": [
    "mean_ar_yearly=mean_ar.mean(dim='year',skipna=True)\n",
    "print(mean_ar_yearly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40790.64\n"
     ]
    }
   ],
   "source": [
    "print(mean_ar_yearly.max().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to file\n",
    "mean_ar_yearly.to_netcdf(\"Mean_AR_IVT.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to file\n",
    "mean_ar.to_netcdf('Mean_AR_GW.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate_py38310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
